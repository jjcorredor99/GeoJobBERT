{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "337e038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JuanJoseCorredor\\miniconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env.prod\")\n",
    "import os\n",
    "from utils.chunker import chunker, chunk_single_text\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a656bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['candidate_id', 'vacant_id', 't_apply', 'stage_max', 'publish_date',\n",
       "       'label', 'vacant_city_loc', 'vacant_full_text', 'vacant_city_ids',\n",
       "       'vacant_remote', 'candidate_full_text', 'candidate_city_loc',\n",
       "       'candidate_city_id', 'candidate_fourier_features',\n",
       "       'no_valid_vacant_city_ids', 'selected_city_id', 'selected_distance',\n",
       "       'exact_match', 'vacant_fourier_feature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_parquet(\"../files/processed/final_datasets/train.parquet\")\n",
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a204a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(os.getenv(\"model_name\"), use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b383e60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JuanJoseCorredor\\miniconda3\\envs\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\JuanJoseCorredor\\.cache\\huggingface\\hub\\models--sentence-transformers--multi-qa-mpnet-base-cos-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model_qa= \"sentence-transformers/multi-qa-mpnet-base-cos-v1\"\n",
    "tokenizer_qa = AutoTokenizer.from_pretrained(model_qa, use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee67e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetTokenizer(name_or_path='sentence-transformers/multi-qa-mpnet-base-cos-v1', vocab_size=30527, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t104: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t30526: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d386a966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetTokenizer(name_or_path='sentence-transformers/all-mpnet-base-v2', vocab_size=30527, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t104: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t30526: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f4518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "vacants = (\n",
    "    ds[[\"vacant_id\", \"vacant_full_text\"]]\n",
    "    .drop_duplicates(\"vacant_id\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "vacant_chunks = vacants[\"vacant_full_text\"].apply(\n",
    "    lambda txt: chunk_single_text(\n",
    "        text=txt,\n",
    "        name=\"job\",          \n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    ").apply(pd.Series)\n",
    "vacant_chunks[\"job_chunks_input_ids\"] = vacant_chunks[\"job_chunks_input_ids\"].map(\n",
    "    lambda x: json.dumps(x, ensure_ascii=False)\n",
    ")\n",
    "vacant_chunks[\"job_chunks_attention_mask\"] = vacant_chunks[\"job_chunks_attention_mask\"].map(\n",
    "    lambda x: json.dumps(x, ensure_ascii=False)\n",
    ")\n",
    "\n",
    "vacants_chunked = pd.concat(\n",
    "    [vacants[[\"vacant_id\"]], vacant_chunks],\n",
    "    axis=1\n",
    ")\n",
    "# columns: vacant_id, job_chunks_input_ids, job_chunks_attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2bb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 2.2 Unique candidates ---\n",
    "cands = (\n",
    "    ds[[\"candidate_id\", \"candidate_full_text\"]]\n",
    "    .drop_duplicates(\"candidate_id\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "cand_chunks = cands[\"candidate_full_text\"].apply(\n",
    "    lambda txt: chunk_single_text(\n",
    "        text=txt,\n",
    "        name=\"cand\",\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    ").apply(pd.Series)\n",
    "cand_chunks[\"cand_chunks_input_ids\"] = cand_chunks[\"cand_chunks_input_ids\"].map(\n",
    "    lambda x: json.dumps(x, ensure_ascii=False)\n",
    ")\n",
    "cand_chunks[\"cand_chunks_attention_mask\"] = cand_chunks[\"cand_chunks_attention_mask\"].map(\n",
    "    lambda x: json.dumps(x, ensure_ascii=False)\n",
    ")\n",
    "\n",
    "cands_chunked = pd.concat(\n",
    "    [cands[[\"candidate_id\"]], cand_chunks],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c47dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = (\n",
    "    ds\n",
    "    .merge(vacants_chunked, on=\"vacant_id\", how=\"left\")\n",
    "    .merge(cands_chunked, on=\"candidate_id\", how=\"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1138a728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['candidate_id', 'vacant_id', 't_apply', 'stage_max', 'publish_date',\n",
       "       'label', 'vacant_city_loc', 'vacant_full_text', 'vacant_city_ids',\n",
       "       'candidate_full_text', 'candidate_city_loc', 'candidate_city_id',\n",
       "       'candidate_fourier_features', 'no_valid_vacant_city_ids',\n",
       "       'selected_city_id', 'selected_distance', 'exact_match',\n",
       "       'vacant_fourier_feature', 'job_chunks_input_ids',\n",
       "       'job_chunks_attention_mask', 'cand_chunks_input_ids',\n",
       "       'cand_chunks_attention_mask'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[['candidate_id', 'vacant_id', 't_apply', 'stage_max', 'publish_date',\n",
    "       'label', 'vacant_full_text', 'vacant_city_ids',\n",
    "       'candidate_full_text', 'candidate_city_id',\n",
    "       'candidate_fourier_features', 'no_valid_vacant_city_ids',\n",
    "       'selected_city_id', 'selected_distance', 'exact_match',\n",
    "       'vacant_fourier_feature', 'job_chunks_input_ids',\n",
    "       'job_chunks_attention_mask', 'cand_chunks_input_ids', 'vacant_remote',\n",
    "       'cand_chunks_attention_mask']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d340ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidate_id                                                                 91\n",
       "vacant_id                                                                245572\n",
       "t_apply                                        2024-02-15 18:32:30.977000+00:00\n",
       "stage_max                                                                   1.0\n",
       "publish_date                                   2024-01-19 12:53:16.588000+00:00\n",
       "label                                                                         0\n",
       "vacant_full_text              Estamos en la\\nbúsqueda de un Auxiliar Jurídic...\n",
       "vacant_city_ids                                                         [16963]\n",
       "candidate_full_text           Abogado especualista en derecho administrativo...\n",
       "candidate_city_id                                                         17050\n",
       "candidate_fourier_features    [0.2214912176, -0.46965277190000004, 0.3965891...\n",
       "no_valid_vacant_city_ids                                                  False\n",
       "selected_city_id                                                          16963\n",
       "selected_distance                                                      0.773318\n",
       "exact_match                                                               False\n",
       "vacant_fourier_feature        [0.17528729140000002, -0.4929802418, -0.499700...\n",
       "job_chunks_input_ids          [[0, 9769, 22595, 2019, 4376, 2478, 3906, 4230...\n",
       "job_chunks_attention_mask     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\n",
       "cand_chunks_input_ids         [[0, 11117, 18174, 3531, 9690, 5055, 10845, 13...\n",
       "cand_chunks_attention_mask    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e969499",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"vacant_city_ids\"] = ds[\"vacant_city_ids\"].map(\n",
    "    lambda x: json.dumps(\n",
    "        x.tolist() if isinstance(x, np.ndarray) else x,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    ")\n",
    "ds[\"vacant_fourier_feature\"] = ds[\"vacant_fourier_feature\"].map(\n",
    "    lambda x: json.dumps(\n",
    "        x.tolist() if isinstance(x, np.ndarray) else x,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    ")\n",
    "ds[\"candidate_fourier_features\"] = ds[\"candidate_fourier_features\"].map(\n",
    "    lambda x: json.dumps(\n",
    "        x.tolist() if isinstance(x, np.ndarray) else x,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.loc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fd8d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora sí, escribir parquet\n",
    "ds.to_parquet(\n",
    "    \"../files/processed/final_datasets/train.parquet\",\n",
    "    engine=\"fastparquet\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
