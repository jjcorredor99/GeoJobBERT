{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac26af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080893d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.utils.encode_latlon import GeoFourierEncoder\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"model\", \"nn.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca2fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 8\n",
    "scales_km = (1200, 400, 150, 50)\n",
    "seed = 0\n",
    "\n",
    "enc = GeoFourierEncoder(D=D, scales_km=scales_km, seed=seed)\n",
    "enc.B = np.load(\"./backend/utils/geo_B.npy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab542a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21255764, -0.47415477,  0.38863727,  0.27267995,  0.4525696 ,\n",
       "         0.15867338, -0.31458077,  0.419101  ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat = 4.641518\n",
    "lon = -74.062047\n",
    "user_feat = enc.transform([[lat, lon]])\n",
    "user_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.utils.chunker import chunker\n",
    "from sqlalchemy import Column, BigInteger, Text, Numeric, Boolean, Float\n",
    "from sqlalchemy.dialects.postgresql import ARRAY\n",
    "from transformers import AutoTokenizer\n",
    "import os \n",
    "\n",
    "class VacancyDB(Base):\n",
    "    __tablename__ = \"vacancies\"\n",
    "\n",
    "    id = Column(BigInteger, primary_key=True, index=True)\n",
    "    title = Column(Text, nullable=False)\n",
    "    description = Column(Text, nullable=False)\n",
    "    salary = Column(Numeric(12, 2))\n",
    "    skills = Column(ARRAY(Text))\n",
    "    sectors = Column(ARRAY(Text))\n",
    "    lat = Column(Float)\n",
    "    lon = Column(Float)\n",
    "    remote = Column(Boolean, default=False)\n",
    "    embedding = Column(ARRAY(Float))  # embedding de la vacante\n",
    "class CandidateDB(Base):\n",
    "    __tablename__ = \"candidates\"\n",
    "\n",
    "    id = Column(BigInteger, primary_key=True, index=True)\n",
    "    title = Column(Text, nullable=False)         # rol del candidato\n",
    "    experiences = Column(Text, nullable=False)   # texto de experiencia/CV\n",
    "    salary = Column(Numeric(12, 2))\n",
    "    skills = Column(ARRAY(Text))\n",
    "    sectors = Column(ARRAY(Text))\n",
    "    lat = Column(Float)\n",
    "    lon = Column(Float)\n",
    "    remote = Column(Boolean, default=False)\n",
    "    embedding = Column(ARRAY(Float))  # embedding del candidato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9bcc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fourier(object:  VacancyDB | CandidateDB):\n",
    "     lat = object.lat\n",
    "     lon = object.lon\n",
    "     D = 8\n",
    "     scales_km = (1200, 400, 150, 50)\n",
    "     seed = 0\n",
    "\n",
    "     enc = GeoFourierEncoder(D=D, scales_km=scales_km, seed=seed)\n",
    "     enc.B = np.load(\"./backend/utils/geo_B.npy\") \n",
    "     enc_loc = enc.transform([[lat, lon]])\n",
    "     return enc_loc\n",
    "\n",
    "\n",
    "def coalesce_list(val):\n",
    "    if isinstance(val, list):\n",
    "        return [str(x) for x in val if x not in (None, \"\", float(\"nan\"))]\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    return [str(val)]\n",
    "\n",
    "def format_section(label, values):\n",
    "    values = coalesce_list(values)\n",
    "    return f\"{label}: \" + \", \".join(values) if values else \"\"\n",
    "\n",
    "def build_text_candidate(candidate:CandidateDB):\n",
    "    columnas = {'experience_descriptions':\" experiencia\", 'skill_names':\" habilidades\", 'sector_names':\" sectores\"}\n",
    "    candidate[\"full_text\"] = candidate[\"candidate_description\"]\n",
    "    for col in columnas: \n",
    "        col_ = candidate[col].apply(lambda x: format_section(columnas[col], x))\n",
    "        candidate[\"full_text\"] += col_\n",
    "    candidate[\"full_text\"] = candidate[\"full_text\"] + candidate[\"candidate_salary\"].apply(lambda x: \" salario: \" + str(x))\n",
    "    return candidate\n",
    "\n",
    "def build_vacant_text(vacancy:VacancyDB):\n",
    "        columnas = {'skill_names':\" habilidades\", 'sector_names':\" sectores\"}\n",
    "\n",
    "        for col in columnas:\n",
    "              vacant_text[col] = vacant_text[col].fillna(\"\") \n",
    "              print(col)\n",
    "              col_ = vacant_text[col].apply(lambda x: format_section(columnas[col], x) if len(x)>0 else \"\")\n",
    "              vacant_text[\"full_text\"] += col_\n",
    "        vacant_text[\"full_text\"] = vacant_text[\"full_text\"] + vacant_text[\"min_salary\"].apply(lambda x: \" salario: \" + str(x)) \n",
    "        vacant_text= vacant_text[\"full_text\"]\n",
    "\n",
    "\n",
    "        return vacant_text\n",
    "\n",
    "def create_fourier_vacants(features,remote:int):\n",
    "     features = np.concat(features, remote)\n",
    "     return features\n",
    "def load_model() -> SiameseTwoTower:\n",
    "     global _model\n",
    "     if _model is None:\n",
    "         if not os.path.exists(MODEL_PATH):\n",
    "             raise RuntimeError(f\"Modelo nn.pt no encontrado en {MODEL_PATH}\")\n",
    "         m = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "         m.eval()\n",
    "         m.to(DEVICE)\n",
    "         _model = m\n",
    "     return _model\n",
    "\n",
    "def compute_affinity(candidate:CandidateDB, vacancy:VacancyDB):\n",
    "     job_text = build_vacant_text(vacancy)\n",
    "     cand_text = build_text_candidate(candidate)\n",
    "     texts = {\"job\": job_text, \"cand\": cand_text}\n",
    "     tokenizer = AutoTokenizer.from_pretrained(os.getenv(\"model_name\"), use_fast=False)\n",
    "\n",
    "     chunks = chunker(texts, tokenizer)\n",
    "     vac_fou = build_fourier(vacancy)\n",
    "     cand_fou = build_fourier(candidate)\n",
    "     vac_fou = create_fourier_vacants(vac_fou, vacancy.remote)\n",
    "\n",
    "     model = load_model( )\n",
    "     job_input_ids = chunks[\"job_input_ids\"].unsqueeze(1)\n",
    "     job_attention_mask = chunks[\"job_attention_mask\"].unsqueeze(1)\n",
    "     cand_input_ids = chunks[\"cand_input_ids\"].unsqueeze(1)\n",
    "     cand_attention_mask = chunks[\"cand_attention_mask\"].unsqueeze(1)\n",
    "     batch = {\n",
    "        \"job_input_ids\": job_input_ids.to(DEVICE),\n",
    "        \"job_attention_mask\": job_attention_mask.to(DEVICE),\n",
    "        \"cand_input_ids\": cand_input_ids.to(DEVICE),\n",
    "        \"cand_attention_mask\": cand_attention_mask.to(DEVICE),\n",
    "        \"vac_loc_fourier\": vac_fou.to(DEVICE),\n",
    "        \"cand_loc_fourier\": cand_fou.to(DEVICE),\n",
    "    }\n",
    "\n",
    "     with torch.no_grad():\n",
    "         z_job, z_cand, logit_scale = model(batch)\n",
    "         logits = (z_job * z_cand).sum(dim=-1) * logit_scale\n",
    "         prob = torch.sigmoid(logits)[0].item()\n",
    "\n",
    "     return float(prob) \n",
    "\n",
    "     \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0b9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
